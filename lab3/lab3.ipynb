{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["%pip install ninja"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c12gihF95RnQ","executionInfo":{"status":"ok","timestamp":1693724375644,"user_tz":-420,"elapsed":4029,"user":{"displayName":"Сергей Тарасов","userId":"03516266885353949010"}},"outputId":"393a3d8d-9ba4-47e5-ad38-5992f7e5b150"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: ninja in /usr/local/lib/python3.10/dist-packages (1.11.1)\n"]}]},{"cell_type":"code","source":["#@markdown ### Код\n","%%writefile kernel.cu\n","\n","#include <torch/extension.h>\n","\n","\n","template <typename scalar_t>\n","__global__ void linear_forward_kernel(\n","    const torch::PackedTensorAccessor32<scalar_t, 2, torch::RestrictPtrTraits> input,\n","    const torch::PackedTensorAccessor32<scalar_t, 2, torch::RestrictPtrTraits> weights,\n","    const torch::PackedTensorAccessor32<scalar_t, 1, torch::RestrictPtrTraits> bias,\n","    torch::PackedTensorAccessor32<scalar_t, 2, torch::RestrictPtrTraits> output) {\n","\n","    auto k = blockIdx.x * blockDim.x + threadIdx.x;\n","    auto i = blockIdx.y * blockDim.y + threadIdx.y;\n","    auto j = blockIdx.z * blockDim.z + threadIdx.z;\n","\n","    bool guard = i < weights.size(0) and j < weights.size(1) and k < input.size(0);\n","\n","    if (guard) {\n","        auto part = input[k][i] * weights[i][j];\n","\n","        if (i == 0) {\n","           part += bias[j];\n","        }\n","\n","        atomicAdd(&output[k][j], part);\n","    }\n","}\n","\n","\n","template <typename scalar_t>\n","__global__ void linear_backward_kernel(\n","    const torch::PackedTensorAccessor32<scalar_t, 2, torch::RestrictPtrTraits> input,\n","    const torch::PackedTensorAccessor32<scalar_t, 2, torch::RestrictPtrTraits> weights,\n","    const torch::PackedTensorAccessor32<scalar_t, 1, torch::RestrictPtrTraits> bias,\n","    const torch::PackedTensorAccessor32<scalar_t, 2, torch::RestrictPtrTraits> d_output,\n","    torch::PackedTensorAccessor32<scalar_t, 2, torch::RestrictPtrTraits> d_input,\n","    torch::PackedTensorAccessor32<scalar_t, 2, torch::RestrictPtrTraits> d_weights,\n","    torch::PackedTensorAccessor32<scalar_t, 1, torch::RestrictPtrTraits> d_bias) {\n","\n","    auto k = blockIdx.x * blockDim.x + threadIdx.x;\n","    auto i = blockIdx.y * blockDim.y + threadIdx.y;\n","    auto j = blockIdx.z * blockDim.z + threadIdx.z;\n","\n","    bool guard = i < weights.size(0) and j < weights.size(1) and k < input.size(0);\n","\n","    if (guard) {\n","        atomicAdd(&d_input[k][i], d_output[k][j] * weights[i][j]);\n","        atomicAdd(&d_weights[i][j], d_output[k][j] * input[k][i]);\n","\n","        if (i == 0) {\n","            atomicAdd(&d_bias[j], d_output[k][j]);\n","        }\n","    }\n","}\n","\n","\n","#define CHECK_CUDA(x) TORCH_CHECK(x.device().is_cuda(), #x \" must be a CUDA tensor\")\n","#define CHECK_CONTIGUOUS(x) TORCH_CHECK(x.is_contiguous(), #x \" must be contiguous\")\n","#define CHECK_ARG(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n","#define CHECK_COMPATIBILITY(x, y, d1, d2) \\\n","    TORCH_CHECK(x.size(d1) == y.size(d2), \\\n","    #x \" must be the same size by dim(\" #d1 \") as \" #y \" by dim(\" #d2 \")\")\n","\n","\n","__forceinline__ unsigned int div_and_ceil(float x, float y) {\n","    return ceil(x / y);\n","}\n","\n","\n","__forceinline__ std::tuple<dim3, dim3> configure_grid(\n","    unsigned int nx, unsigned int ny, unsigned int nz) {\n","\n","    const dim3 block_size = {4, 8, 4};\n","\n","    const dim3 grid_size = {\n","        div_and_ceil(nx, block_size.x),\n","        div_and_ceil(ny, block_size.y),\n","        div_and_ceil(nz, block_size.z)\n","    };\n","\n","    return {grid_size, block_size};\n","}\n","\n","\n","torch::Tensor linear_forward(\n","    torch::Tensor input,\n","    torch::Tensor weights,\n","    torch::Tensor bias) {\n","\n","    CHECK_ARG(input);\n","    CHECK_ARG(weights);\n","    CHECK_ARG(bias);\n","\n","    CHECK_COMPATIBILITY(input, weights, 1, 0);\n","    CHECK_COMPATIBILITY(bias, weights, 0, 1);\n","\n","    auto output = torch::zeros({input.size(0), weights.size(1)}, input.options());\n","\n","    dim3 grid_size, block_size;\n","    std::tie(grid_size, block_size) = configure_grid(\n","        input.size(0), input.size(1), weights.size(1));\n","\n","    AT_DISPATCH_FLOATING_TYPES(\n","        input.type(),\n","        \"linear_forward\",\n","        ([&] {\n","            linear_forward_kernel<<<grid_size, block_size>>>(\n","                input.packed_accessor32<scalar_t, 2, torch::RestrictPtrTraits>(),\n","                weights.packed_accessor32<scalar_t, 2, torch::RestrictPtrTraits>(),\n","                bias.packed_accessor32<scalar_t, 1, torch::RestrictPtrTraits>(),\n","                output.packed_accessor32<scalar_t, 2, torch::RestrictPtrTraits>()\n","            );\n","        })\n","    );\n","\n","    return output;\n","}\n","\n","\n","std::vector<torch::Tensor> linear_backward(\n","    torch::Tensor input,\n","    torch::Tensor weights,\n","    torch::Tensor bias,\n","    torch::Tensor d_output) {\n","\n","    CHECK_ARG(input);\n","    CHECK_ARG(weights);\n","    CHECK_ARG(bias);\n","    CHECK_ARG(d_output);\n","\n","    CHECK_COMPATIBILITY(input, weights, 1, 0);\n","    CHECK_COMPATIBILITY(bias, weights, 0, 1);\n","    CHECK_COMPATIBILITY(d_output, weights, 1, 1);\n","    CHECK_COMPATIBILITY(d_output, bias, 1, 0);\n","\n","    auto d_input = torch::zeros_like(input);\n","    auto d_weights = torch::zeros_like(weights);\n","    auto d_bias = torch::zeros_like(bias);\n","\n","    dim3 grid_size, block_size;\n","    std::tie(grid_size, block_size) = configure_grid(\n","        input.size(0), input.size(1), weights.size(1));\n","\n","    AT_DISPATCH_FLOATING_TYPES(\n","        input.type(),\n","        \"linear_backward\",\n","        ([&] {\n","            linear_backward_kernel<<<grid_size, block_size>>>(\n","                input.packed_accessor32<scalar_t, 2, torch::RestrictPtrTraits>(),\n","                weights.packed_accessor32<scalar_t, 2, torch::RestrictPtrTraits>(),\n","                bias.packed_accessor32<scalar_t, 1, torch::RestrictPtrTraits>(),\n","                d_output.packed_accessor32<scalar_t, 2, torch::RestrictPtrTraits>(),\n","                d_input.packed_accessor32<scalar_t, 2, torch::RestrictPtrTraits>(),\n","                d_weights.packed_accessor32<scalar_t, 2, torch::RestrictPtrTraits>(),\n","                d_bias.packed_accessor32<scalar_t, 1, torch::RestrictPtrTraits>()\n","            );\n","        })\n","    );\n","\n","    return {d_input, d_weights, d_bias};\n","}\n","\n","\n","PYBIND11_MODULE(TORCH_EXTENSION_NAME, m) {\n","    m.def(\"linear_forward\", &linear_forward, \"Custom linear layer (forward)\");\n","    m.def(\"linear_backward\", &linear_backward, \"Custom linear layer (backward)\");\n","}"],"metadata":{"id":"rUVbbM2amOLe","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1693724375645,"user_tz":-420,"elapsed":98,"user":{"displayName":"Сергей Тарасов","userId":"03516266885353949010"}},"outputId":"fca0c605-7da9-4686-e2a3-c17e0830d71f"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting kernel.cu\n"]}]},{"cell_type":"code","source":["import torch\n","from torch.utils.cpp_extension import load\n","\n","\n","my_ext = load(\n","    name='my_extension',\n","    sources=['kernel.cu'],\n","    extra_cuda_cflags=[\n","        '-std=c++17',\n","        '--extended-lambda',\n","        '-O3', '-gencode arch=compute_75,code=sm_75'\n","    ],\n","    extra_cflags=['-O3'],\n",")"],"metadata":{"id":"vfDsDU5c4rHq","executionInfo":{"status":"ok","timestamp":1693724458384,"user_tz":-420,"elapsed":82744,"user":{"displayName":"Сергей Тарасов","userId":"03516266885353949010"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["class LinearFunction(torch.autograd.Function):\n","    @staticmethod\n","    def forward(ctx, input, weights, bias):\n","        ctx.save_for_backward(input, weights, bias)\n","        return my_ext.linear_forward(input, weights, bias)\n","\n","    @staticmethod\n","    def backward(ctx, d_output):\n","        d_input, d_weights, d_bias = my_ext.linear_backward(\n","            *ctx.saved_tensors, d_output)\n","        return d_input, d_weights, d_bias"],"metadata":{"id":"nzz3yVj5vnOX","executionInfo":{"status":"ok","timestamp":1693724751631,"user_tz":-420,"elapsed":363,"user":{"displayName":"Сергей Тарасов","userId":"03516266885353949010"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["torch.manual_seed(27)\n","\n","x = torch.rand((4, 8), device='cuda', requires_grad=True)\n","w1 = torch.rand((8, 5), device='cuda', requires_grad=True)\n","b1 = torch.rand((5, ), device='cuda', requires_grad=True)\n","w2 = torch.rand((5, 4), device='cuda', requires_grad=True)\n","b2 = torch.rand((4, ), device='cuda', requires_grad=True)\n","y = LinearFunction.apply(x, w1, b1)\n","z = LinearFunction.apply(y, w2, b2)\n","\n","z.backward(torch.ones_like(z))\n","\n","x_ = x.detach().clone().requires_grad_()\n","w1_ = w1.detach().clone().requires_grad_()\n","b1_ = b1.detach().clone().requires_grad_()\n","w2_ = w2.detach().clone().requires_grad_()\n","b2_ = b2.detach().clone().requires_grad_()\n","y_ = x_ @ w1_ + b1_\n","z_ = y_ @ w2_ + b2_\n","\n","z_.backward(torch.ones_like(z_))\n","\n","assert torch.allclose(x_.grad, x.grad)\n","assert torch.allclose(w1_.grad, w1.grad)\n","assert torch.allclose(b1_.grad, b1.grad)\n","assert torch.allclose(w2_.grad, w2.grad)\n","assert torch.allclose(b2_.grad, b2.grad)\n","\n","print(\"The tests passed successfully.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OF3ZUt1hzEuP","executionInfo":{"status":"ok","timestamp":1693724755314,"user_tz":-420,"elapsed":478,"user":{"displayName":"Сергей Тарасов","userId":"03516266885353949010"}},"outputId":"ffff86e8-09b2-4337-ec74-c343c94f6323"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["The tests passed successfully.\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"kMu9NSAE2qeM"},"execution_count":null,"outputs":[]}]}